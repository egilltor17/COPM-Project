{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "d04fddb330a34ef732f1cba10e5f48b21f6eea07c886cdf995b436f2f43760b6"
        }
      }
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6wslvfp2CfN",
        "outputId": "f1a3c59c-2689-4ecf-e237-b2f2dd4e605d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            "Cloning into 'COPM-Project'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 58 (delta 17), reused 53 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMa0QPhU5wD4"
      },
      "source": [
        "!git clone https://github.com/egilltor17/COPM-Project.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D70J4lsh2gUS",
        "outputId": "e77c7ad4-f714-48f7-9ac1-0d8682354c39"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'COPM-Project'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d8d0xfjd1j0B",
        "outputId": "cad85ee4-067a-4e3f-92ce-198f1e32a728"
      },
      "source": [
        "import os\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "!pip install Visdom\n",
        "from visdom import Visdom\n",
        "\n",
        "from dataset.dataset import Dataset\n",
        "\n",
        "from loss.Dice import DiceLoss\n",
        "from loss.ELDice import ELDiceLoss\n",
        "from loss.WBCE import WCELoss\n",
        "from loss.Jaccard import JaccardLoss\n",
        "from loss.SS import SSLoss\n",
        "from loss.Tversky import TverskyLoss\n",
        "from loss.Hybrid import HybridLoss\n",
        "from loss.BCE import BCELoss\n",
        "\n",
        "from net.ResUNet import net\n",
        "\n",
        "import parameter as para\n",
        "\n",
        "# 设置visdom\n",
        "viz = Visdom(port=666)\n",
        "step_list = [0]\n",
        "win = viz.line(X=np.array([0]), Y=np.array([1.0]), opts=dict(title='loss'))\n",
        "\n",
        "# 设置显卡相关\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = para.gpu\n",
        "cudnn.benchmark = para.cudnn_benchmark\n",
        "\n",
        "# 定义网络\n",
        "net = torch.nn.DataParallel(net).cuda()\n",
        "net.train()\n",
        "\n",
        "# 定义Dateset\n",
        "train_ds = Dataset(os.path.join(para.training_set_path, 'ct'), os.path.join(para.training_set_path, 'seg'))\n",
        "\n",
        "# 定义数据加载\n",
        "train_dl = DataLoader(train_ds, para.batch_size, True, num_workers=para.num_workers, pin_memory=para.pin_memory)\n",
        "\n",
        "# 挑选损失函数\n",
        "loss_func_list = [DiceLoss(), ELDiceLoss(), WCELoss(), JaccardLoss(), SSLoss(), TverskyLoss(), HybridLoss(), BCELoss()]\n",
        "loss_func = loss_func_list[5]\n",
        "\n",
        "# 定义优化器\n",
        "opt = torch.optim.Adam(net.parameters(), lr=para.learning_rate)\n",
        "\n",
        "# 学习率衰减\n",
        "lr_decay = torch.optim.lr_scheduler.MultiStepLR(opt, para.learning_rate_decay)\n",
        "\n",
        "# 深度监督衰减系数\n",
        "alpha = para.alpha\n",
        "\n",
        "# 训练网络\n",
        "start = time()\n",
        "for epoch in range(para.Epoch):\n",
        "\n",
        "    lr_decay.step()\n",
        "\n",
        "    mean_loss = []\n",
        "\n",
        "    for step, (ct, seg) in enumerate(train_dl):\n",
        "\n",
        "        ct = ct.cuda()\n",
        "        seg = seg.cuda()\n",
        "\n",
        "        outputs = net(ct)\n",
        "\n",
        "        loss1 = loss_func(outputs[0], seg)\n",
        "        loss2 = loss_func(outputs[1], seg)\n",
        "        loss3 = loss_func(outputs[2], seg)\n",
        "        loss4 = loss_func(outputs[3], seg)\n",
        "\n",
        "        loss = (loss1 + loss2 + loss3) * alpha + loss4\n",
        "\n",
        "        mean_loss.append(loss4.item())\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if step % 5 is 0:\n",
        "            \n",
        "            step_list.append(step_list[-1] + 1)\n",
        "            viz.line(X=np.array([step_list[-1]]), Y=np.array([loss4.item()]), win=win, update='append')\n",
        "            \n",
        "            print('epoch:{}, step:{}, loss1:{:.3f}, loss2:{:.3f}, loss3:{:.3f}, loss4:{:.3f}, time:{:.3f} min'\n",
        "                  .format(epoch, step, loss1.item(), loss2.item(), loss3.item(), loss4.item(), (time() - start) / 60))\n",
        "\n",
        "    mean_loss = sum(mean_loss) / len(mean_loss)\n",
        "\n",
        "    # 保存模型\n",
        "    if epoch % 50 is 0 and epoch is not 0:\n",
        "\n",
        "        # 网络模型的命名方式为：epoch轮数+当前minibatch的loss+本轮epoch的平均loss\n",
        "        torch.save(net.state_dict(), './module/net{}-{:.3f}-{:.3f}.pth'.format(epoch, loss, mean_loss))\n",
        "\n",
        "    # 对深度监督系数进行衰减\n",
        "    if epoch % 40 is 0 and epoch is not 0:\n",
        "        alpha *= 0.8\n",
        "\n",
        "# 深度监督的系数变化\n",
        "# 1.000\n",
        "# 0.800\n",
        "# 0.640\n",
        "# 0.512\n",
        "# 0.410\n",
        "# 0.328\n",
        "# 0.262\n",
        "# 0.210\n",
        "# 0.168\n",
        "# 0.134\n",
        "# 0.107\n",
        "# 0.086\n",
        "# 0.069\n",
        "# 0.055\n",
        "# 0.044\n",
        "# 0.035\n",
        "# 0.028\n",
        "# 0.023\n",
        "# 0.018\n",
        "# 0.014\n",
        "# 0.012\n",
        "# 0.009\n",
        "# 0.007\n",
        "# 0.006\n",
        "# 0.005\n",
        "# 0.004\n",
        "# 0.003\n",
        "# 0.002\n",
        "# 0.002\n",
        "# 0.002\n",
        "# 0.001\n",
        "# 0.001\n",
        "# 0.001\n",
        "# 0.001\n",
        "# 0.001\n",
        "# 0.000\n",
        "# 0.000\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 9.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 419kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 450kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 481kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 512kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 532kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 563kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 624kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 645kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 665kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from Visdom) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from Visdom) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from Visdom) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from Visdom) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from Visdom) (20.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from Visdom) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from Visdom) (7.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->Visdom) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->Visdom) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->Visdom) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->Visdom) (2.10)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: Visdom, torchfile\n",
            "  Building wheel for Visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655251 sha256=67f57c96f2de5144c310c00d005241251f2503f8a5d305addebeef1d81d56fea\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=857a9feb07144222e38b8c68e39dc0a6e2133f7ef419dd95ec8e0c5e44edc31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built Visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, Visdom\n",
            "Successfully installed Visdom-0.1.8.9 jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3be611967730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvisdom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisdom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiceLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}